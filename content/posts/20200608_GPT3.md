---
title: 'GPT3: Few shot leaner'
date: 2020-06-08
tags: ['nlp', 'paper']
description: 'GPT3 notes'
draft: false
hide: false
---

GPT3在network architecture上與GPT2並無不同, 就是將它加大加深, 用來training的資料更多而已, 175B的parameter數與410B的training token已完全超乎一般人想象

傳統上來說我們一般將這種general的pretrained model用在fine tune上, GPT3這篇paper主要是要表示當我們的general model夠大夠強的時候, 我們可以完全不需要額外的training就直接將model用在downstream task上而表現的不錯

## Reference
* [GPT3 Original Paper](https://arxiv.org/abs/2005.14165)  
* [GPT3 explained video by Yannic Kilcher](https://www.youtube.com/watch?v=SY5PvZrJhLE)  