---
title: "Url Shortner"
date: 2022-05-17
tags: ['system-design']
draft: false
hide: false
---

## Outline
* API interface
* Back of envelop analasis
* How to generate short url
    + Hash + RDBMS
    + Increasing ID + ZooKeeper + KV DB
* How to get the original url
    + cache
    + expire

## API Interface
* create_short_url(long_url string, expire_time time) -> short_url string
* redirect(short_url string) -> HTTP 302 to long_url

## Analasis
* compute the create rate, read rate
* if the create rate is less than 1000/s, you can consider the sql solution bellow

## How to generate short url
### Hash + RDBMS
* use murmurhash32 to convert long_url to 32bit integer
    + Not encrypt, so performance better
    + low collision rate
* use base62 to encode it
    + guarantee the generated string would not have special chars
    + reduce the length
* trim it to only length 8 as our short_url
* store (short_url, long_url, expire_time) into DB
* how to deal with collision(if 2 different long_url map to the same short_url)
    + check duplication by set short_url uniqeness in RDBMS
    + generate new short_url by long_url_duplicate_1
* Pros and Cons
    + Pros: have a fixed length short_url, same long_url will never generate different short_url
    + Cons: Need to use RDBMD unique or some other technique to prevent collision

### Increasing ID + ZooKeeper + KV DB
* we will use an globally increased id and encode it by base62 to generate our short_url
    + because it is generated by an globally increased id so it will be guarantted to be unique
    + store short_url -> long_url, expire_time into some KV DB
* How to scale this solution
    + we store the id range pool and the corresponding server into ZooKeeper
        - [0 - 10000]: 1st server
        - [10001 - 20000]: 2nd server
        - [20001 - 30000]: 3rd server
        - [30001 - 40000]: None
        - ...etc
    + when the id pool of 1st is used out, then 1st server will ask ZooKeeper to give it a new pool
    + how about if 1st dies? when it comes back again, the zookeeper will give it a new pool, so yes, if there still some unused ids in the original pool then they will all be wasted
* How to deal with the problem that 2 identical long_url will generate 2 different short_url
    + store the long_url -> short_url into redis, set the ttl to 1 day
    + if we can find the duplicate long_url, then return the stored short_url directly
* Pros and Cons
    + Pros: No collision and we don't need to use RDBMS
    + Cons: The generated sequence will becomes longer and longer


## How to get the original url
* when user get an existed url, we can store it into our cache(Redis)
* how about the expire??
    + when user call redirct, if now > expire_time, then we return 404
    + have an offline process to clear the expired_data(also clear data in cache)

